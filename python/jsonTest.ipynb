{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"t\": \"21:48:00\", \"x\": 28.0}, {\"t\": \"21:49:00\", \"x\": 31.0}, {\"t\": \"21:50:00\", \"x\": 36.0}, {\"t\": \"21:51:00\", \"x\": 43.0}, {\"t\": \"21:52:00\", \"x\": 46.0}, {\"t\": \"21:53:00\", \"x\": 52.0}, {\"t\": \"21:54:00\", \"x\": 55.0}, {\"t\": \"21:55:00\", \"x\": 59.0}, {\"t\": \"21:56:00\", \"x\": 58.0}, {\"t\": \"21:57:00\", \"x\": 55.0}, {\"t\": \"21:58:00\", \"x\": 47.0}, {\"t\": \"21:59:00\", \"x\": 40.0}, {\"t\": \"22:00:00\", \"x\": 35.0}, {\"t\": \"22:01:00\", \"x\": 40.0}, {\"t\": \"22:02:00\", \"x\": 46.0}, {\"t\": \"22:03:00\", \"x\": 55.0}, {\"t\": \"22:04:00\", \"x\": 60.0}, {\"t\": \"22:05:00\", \"x\": 68.0}, {\"t\": \"22:06:00\", \"x\": 72.0}, {\"t\": \"22:07:00\", \"x\": 75.0}, {\"t\": \"22:08:00\", \"x\": 70.0}, {\"t\": \"22:09:00\", \"x\": 66.0}, {\"t\": \"22:10:00\", \"x\": 58.0}, {\"t\": \"22:11:00\", \"x\": 50.0}, {\"t\": \"22:12:00\", \"x\": 45.0}, {\"t\": \"22:13:00\", \"x\": 49.0}, {\"t\": \"22:14:00\", \"x\": 57.0}, {\"t\": \"22:15:00\", \"x\": 68.0}, {\"t\": \"22:16:00\", \"x\": 78.0}, {\"t\": \"22:17:00\", \"x\": 80.0}, {\"t\": \"22:18:00\", \"x\": 88.0}, {\"t\": \"22:19:00\", \"x\": 90.0}, {\"t\": \"22:20:00\", \"x\": 84.0}, {\"t\": \"22:21:00\", \"x\": 80.0}, {\"t\": \"22:22:00\", \"x\": 57.0}, {\"t\": \"22:23:00\", \"x\": 60.0}]\n"
     ]
    }
   ],
   "source": [
    "# Read data from CSV\n",
    "data = pd.read_csv('./dataset/sales/Monthly sales of soft drink hundreds of cases p272 Montgomery.csv')\n",
    "data.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "now = datetime.datetime.now()\n",
    "if now.second > 0:\n",
    "    now = now.replace(second=0, microsecond=0) - datetime.timedelta(minutes=35)\n",
    "data.index = pd.date_range(now, freq='min', periods=len(data))\n",
    "\n",
    "# Split data into train and test sets\n",
    "size = 36\n",
    "train, test = data['x'][0:size], data['x'][size:len(data)]\n",
    "\n",
    "train_data = []\n",
    "for i in range(len(train)):\n",
    "    t = train.index[i].strftime('%H:%M:%S')\n",
    "    value = float(train[i])\n",
    "    train_data.append({'t': t, 'x': value})\n",
    "\n",
    "train_json = json.dumps(train_data)\n",
    "print(train_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://localhost:3000/' \n",
    "static_url = url + 'static/meritve.json'\n",
    "post_url = url + 'krmilnik'\n",
    "\n",
    "df = pd.read_json(static_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "sarima_model = SARIMAX(df['x'],order = (1,1,3),seasonal_order = (0,1,1,12))\n",
    "sarima_fit = sarima_model.fit()\n",
    "sarima_pred = sarima_fit.forecast(steps=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df['x'])\n",
    "plt.plot(sarima_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AMD\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency T will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\AMD\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:471: ValueWarning: No frequency information was provided, so inferred frequency T will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "C:\\Users\\AMD\\anaconda3\\lib\\site-packages\\statsmodels\\tsa\\statespace\\sarimax.py:866: UserWarning: Too few observations to estimate starting parameters for seasonal ARMA. All parameters except for variances will be set to zeros.\n",
      "  warn('Too few observations to estimate starting parameters%s.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-22 22:24:00    0.978698\n",
      "2023-02-22 22:25:00    0.983795\n",
      "2023-02-22 22:26:00    1.159971\n",
      "2023-02-22 22:27:00    1.336961\n",
      "2023-02-22 22:28:00    1.559757\n",
      "2023-02-22 22:29:00    1.507421\n",
      "2023-02-22 22:30:00    1.685076\n",
      "2023-02-22 22:31:00    1.708962\n",
      "2023-02-22 22:32:00    1.623083\n",
      "2023-02-22 22:33:00    1.559335\n",
      "2023-02-22 22:34:00    1.012044\n",
      "2023-02-22 22:35:00    1.186565\n",
      "Freq: T, Name: predicted_mean, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url = 'http://localhost:3000/' \n",
    "static_url = url + 'static/meritve.json'\n",
    "post_url = url + 'krmilnik'\n",
    "\n",
    "df = pd.read_json(static_url)\n",
    "\n",
    "# Convert 't' column to datetime\n",
    "df['t'] = pd.to_datetime(df['t'])\n",
    "\n",
    "# Set 't' column as index\n",
    "df.set_index('t', inplace=True)\n",
    "\n",
    "# Define SARIMA model and fit to data\n",
    "sarima_model = SARIMAX(df['x'], order=(1,1,3), seasonal_order=(0,1,1,12))\n",
    "sarima_fit = sarima_model.fit()\n",
    "\n",
    "# Use the index to create a new DataFrame with predicted values and timestamps\n",
    "# simulacija pretoka(delim z 60 da dobimo realne vrednosti)\n",
    "sarima_pred = sarima_fit.forecast(steps=12)/60\n",
    "\n",
    "# Print the predicted values and timestamps\n",
    "print(sarima_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Temp_trans(dmpm, u=1, t=60.):\n",
    "    dm=dmpm/60 #kg/s\n",
    "    m=10.\n",
    "    P=2000.\n",
    "    c=4184.\n",
    "    Tmv=20.\n",
    "    Ttv=50.\n",
    "    T = (-P*u*t/(m*c)-dm/m*t*Tmv+Ttv)/(1-dm/m*t)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"d\": \"2023-02-22 22:24:00\", \"T\": 50.0}, {\"d\": \"2023-02-22 22:25:00\", \"T\": 50.0}, {\"d\": \"2023-02-22 22:26:00\", \"T\": 51.0}, {\"d\": \"2023-02-22 22:27:00\", \"T\": 51.0}, {\"d\": \"2023-02-22 22:28:00\", \"T\": 52.0}, {\"d\": \"2023-02-22 22:29:00\", \"T\": 52.0}, {\"d\": \"2023-02-22 22:30:00\", \"T\": 53.0}, {\"d\": \"2023-02-22 22:31:00\", \"T\": 53.0}, {\"d\": \"2023-02-22 22:32:00\", \"T\": 52.0}, {\"d\": \"2023-02-22 22:33:00\", \"T\": 52.0}, {\"d\": \"2023-02-22 22:34:00\", \"T\": 50.0}, {\"d\": \"2023-02-22 22:35:00\", \"T\": 51.0}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Iterate through the series and create a list of dictionaries\n",
    "data = []\n",
    "for timestamp, value in sarima_pred.items():\n",
    "    tVal = round(Temp_trans(value), 0)\n",
    "    data.append({'d': str(timestamp), 'T': tVal})\n",
    "\n",
    "# Convert the list to a JSON string\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "print(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'d': '2023-02-22 22:24:00', 'T': 50.0}, {'d': '2023-02-22 22:26:00', 'T': 51.0}, {'d': '2023-02-22 22:28:00', 'T': 52.0}, {'d': '2023-02-22 22:30:00', 'T': 53.0}, {'d': '2023-02-22 22:32:00', 'T': 52.0}, {'d': '2023-02-22 22:34:00', 'T': 50.0}, {'d': '2023-02-22 22:35:00', 'T': 51.0}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data = []\n",
    "lastVal = None\n",
    "\n",
    "for timestamp, value in sarima_pred.items():\n",
    "    tVal = round(Temp_trans(value), 0)\n",
    "    if tVal != lastVal:\n",
    "        data.append({'d': str(timestamp), 'T': tVal})\n",
    "    \n",
    "    lastVal = tVal\n",
    "\n",
    "schedule_data_json = json.dumps(data)\n",
    "schedule_data = json.loads(schedule_data_json)\n",
    "print(schedule_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(post_url, json=schedule_data)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
